# ğŸ•µï¸â€â™‚ï¸ DOEPI-Scrapper-Gemini

Um coletor (scraper) automatizado para o DiÃ¡rio Oficial do Estado do PiauÃ­ (DOE-PI) com foco em extraÃ§Ã£o e organizaÃ§Ã£o de documentos relevantes (decretos, diÃ¡rios oficiais, nomeaÃ§Ãµes/exoneraÃ§Ãµes etc.), possivelmente integrando capacidades de IA para auxiliar no processamento e anÃ¡lise de conteÃºdo.
Este projeto foi desenvolvido para automatizar a captura e prÃ©-processamento de documentos pÃºblicos, facilitando o uso dos dados em aplicaÃ§Ãµes de busca, anÃ¡lise ou consulta automatizada.
O projeto foi paralizado em Setembro de 2025, mas serÃ¡ continuado.

## ğŸ§  Funcionalidade

âœ” Baixa conteÃºdo pÃºblico do DiÃ¡rio Oficial do Estado do PiauÃ­
âœ” Organiza documentos por tipo (decretos, diÃ¡rios, ato administrativo, etc.)
âœ” Possibilidade de integraÃ§Ã£o com modelos de IA (como Gemini ou outro) para anÃ¡lise ou classificaÃ§Ã£o dos textos
âœ” Interface Python simples para automaÃ§Ã£o

## ğŸ“‚ Estrutura do RepositÃ³rio

â”œâ”€â”€ decretos/                  # Decretos extraÃ­dos
â”œâ”€â”€ diario/                    # Arquivos ou PDFs de diÃ¡rios oficiais
â”œâ”€â”€ front/                     # CÃ³digo front-end (interface de visualizaÃ§Ã£o?)
â”œâ”€â”€ nomeaÃ§Ãµes eou exoneraÃ§Ãµes/ # NomeaÃ§Ãµes e exoneraÃ§Ãµes capturadas
â”œâ”€â”€ pdf_searcher/              # Scripts para localizar e extrair texto de PDFs
â”œâ”€â”€ scrapper/                  # Scripts de scraping
â”œâ”€â”€ main.py                    # Script principal de execuÃ§Ã£o
â””â”€â”€ readme.md                  # Documento com instruÃ§Ãµes (atualmente vazio)

## ğŸš€ InstalaÃ§Ã£o

Clone o repositÃ³rio:

git clone https://github.com/carlos-dani-dev/doepi-scrapper-gemini.git
cd doepi-scrapper-gemini


Crie um ambiente virtual (recomendado):

python3 -m venv venv
source venv/bin/activate   # macOS/Linux
venv\Scripts\activate      # Windows


Instale as dependÃªncias (se houver um requirements.txt):

pip install -r requirements.txt

## â–¶ï¸ Como Usar
ğŸª 1. Configurar variÃ¡veis / parÃ¢metros

Antes de rodar o scraper, ajuste as configuraÃ§Ãµes no main.py ou nos scripts correspondentes para indicar:

âœ” URLs de onde os dados devem ser extraÃ­dos
âœ” PadrÃµes de arquivos que vocÃª deseja baixar
âœ” Local de saÃ­da dos dados

ğŸ§¾ 2. Executar o scraper
python main.py


O script principal (main.py) deve iniciar o processo de coleta de documentos, salvar os PDFs/textos localmente e organizÃ¡-los nas pastas correspondentes.

ğŸ§  3. (Opcional) Processar textos com IA

Se o projeto integrar algum mÃ³dulo de IA (por exemplo, usando um modelo como Gemini para resumo/classificaÃ§Ã£o), adicione as chaves de API necessÃ¡rias e ajuste os mÃ³dulos para processar os textos extraÃ­dos.

## ğŸ§° PossÃ­veis usos

âœ… Pesquisa automatizada no DiÃ¡rio Oficial
âœ… ExtraÃ§Ã£o e classificaÃ§Ã£o de atos administrativos
âœ… ConstruÃ§Ã£o de bases de dados para anÃ¡lise jurÃ­dica ou de polÃ­ticas pÃºblicas
âœ… IntegraÃ§Ã£o com chatbots ou ferramentas de busca semÃ¢ntica

